{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Sage: Financial News Insight Application\n",
    "\n",
    "Market Sage is a proof-of-concept application that extracts financial news insights by combining traditional NLP techniques with text summarization powered by GPT-Neo. This notebook documents the entire pipeline, including:\n",
    "\n",
    "- **Section 0:** Overview & Project Setup\n",
    "- **Section 1:** Merged Data Acquisition from Multiple Free RSS Feeds\n",
    "- **Section 2:** Model Training and Preprocessing (`model_training.py`)\n",
    "- **Section 3:** GPT-Neo API Service Setup (`gptneo_service.py`)\n",
    "- **Section 4:** Flask App Integration (`app.py`) and Minimal HTML Front-End\n",
    "- **Section 5:** Running the Complete Pipeline\n",
    "- **Section 6:** Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Overview & Project Setup\n",
    "\n",
    "In this project, we build a robust financial news dataset by aggregating articles from multiple free RSS feeds. These sources include:\n",
    "- Yahoo Finance\n",
    "- Reuters\n",
    "- CNBC\n",
    "- MSN Finance\n",
    "- Google News (as a proxy for Google Finance)\n",
    "\n",
    "Then, we train a sentiment classifier using a Naive Bayes model and integrate a GPT-Neoâ€“powered summarization service via FastAPI. Finally, a Flask app with a simple HTML front-end displays the results.\n",
    "\n",
    "Before proceeding, set up a virtual environment and install the required packages (see Section 5 for details on `requirements.txt`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Merged Data Acquisition from Multiple Free RSS Feeds\n",
    "\n",
    "In this section, we merge data acquisition from multiple free RSS sources into one script. This script fetches articles from several sources and merges them into one CSV file (`sample_data.csv`). Save this cell as `data_acquisition_master.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# %% [code] \"data_acquisition_master.py\"\\nimport feedparser  # Library to parse RSS feeds\\nimport pandas as pd  # For creating and managing DataFrames\\n\\n# Function to fetch news from Yahoo Finance\\ndef fetch_yahoo_finance():\\n    # RSS feed URL for Yahoo Finance (example: AAPL headlines)\\n    rss_url = \"https://feeds.finance.yahoo.com/rss/2.0/headline?s=AAPL&region=US&lang=en-US\"\\n    feed = feedparser.parse(rss_url)  # Parse the RSS feed\\n    news_items = []\\n    # Loop over each entry in the feed\\n    for entry in feed.entries:\\n        title = entry.title  # Get the article title\\n        # Get the summary if it exists; otherwise, use an empty string\\n        summary = entry.summary if hasattr(entry, \\'summary\\') else \"\"\\n        # Combine title and summary to form full text\\n        text = title + \". \" + summary\\n        # Append the news article as a dictionary with a default sentiment label \"neutral\"\\n        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"Yahoo Finance\"})\\n    return news_items\\n\\n# Function to fetch news from Reuters Business News RSS feed\\ndef fetch_reuters_finance():\\n    rss_url = \"http://feeds.reuters.com/reuters/businessNews\"\\n    feed = feedparser.parse(rss_url)\\n    news_items = []\\n    for entry in feed.entries:\\n        title = entry.title\\n        summary = entry.summary if hasattr(entry, \\'summary\\') else \"\"\\n        text = title + \". \" + summary\\n        # Specify source as Reuters\\n        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"Reuters\"})\\n    return news_items\\n\\n# Function to fetch news from CNBC RSS feed\\ndef fetch_cnbc_finance():\\n    rss_url = \"https://www.cnbc.com/id/100003114/device/rss/rss.html\"\\n    feed = feedparser.parse(rss_url)\\n    news_items = []\\n    for entry in feed.entries:\\n        title = entry.title\\n        summary = entry.summary if hasattr(entry, \\'summary\\') else \"\"\\n        text = title + \". \" + summary\\n        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"CNBC\"})\\n    return news_items\\n\\n# Function to fetch news from MSN Finance RSS feed\\ndef fetch_msn_finance():\\n    # Example URL for MSN Money RSS feed (adjust URL if needed)\\n    rss_url = \"https://www.msn.com/en-us/money/rss\"\\n    feed = feedparser.parse(rss_url)\\n    news_items = []\\n    for entry in feed.entries:\\n        title = entry.title\\n        summary = entry.summary if hasattr(entry, \\'summary\\') else \"\"\\n        text = title + \". \" + summary\\n        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"MSN Finance\"})\\n    return news_items\\n\\n# Function to fetch finance-related news from Google News (proxy for Google Finance)\\ndef fetch_google_finance():\\n    # Google News RSS feed URL for finance search query\\n    rss_url = \"https://news.google.com/rss/search?q=finance&hl=en-US&gl=US&ceid=US:en\"\\n    feed = feedparser.parse(rss_url)\\n    news_items = []\\n    for entry in feed.entries:\\n        title = entry.title\\n        summary = entry.summary if hasattr(entry, \\'summary\\') else \"\"\\n        text = title + \". \" + summary\\n        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"Google News\"})\\n    return news_items\\n\\n# Function to merge all articles from the different sources\\ndef merge_all_articles():\\n    # Call each individual fetch function\\n    yahoo_articles = fetch_yahoo_finance()\\n    reuters_articles = fetch_reuters_finance()\\n    cnbc_articles = fetch_cnbc_finance()\\n    msn_articles = fetch_msn_finance()\\n    google_articles = fetch_google_finance()\\n    \\n    # Combine all article lists into one\\n    all_articles = yahoo_articles + reuters_articles + cnbc_articles + msn_articles + google_articles\\n    return all_articles\\n\\n# Main execution block: merge articles and save as CSV\\nif __name__ == \"__main__\":\\n    articles = merge_all_articles()  # Get merged list of articles\\n    # Convert the list of dictionaries into a pandas DataFrame\\n    df = pd.DataFrame(articles)\\n    # Save DataFrame to CSV file named \\'sample_data.csv\\'\\n    df.to_csv(\"sample_data.csv\", index=False)\\n    print(\"Merged sample_data.csv created with\", len(df), \"entries\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# %% [code] \"data_acquisition_master.py\"\n",
    "import feedparser  # Library to parse RSS feeds\n",
    "import pandas as pd  # For creating and managing DataFrames\n",
    "\n",
    "# Function to fetch news from Yahoo Finance\n",
    "def fetch_yahoo_finance():\n",
    "    # RSS feed URL for Yahoo Finance (example: AAPL headlines)\n",
    "    rss_url = \"https://feeds.finance.yahoo.com/rss/2.0/headline?s=AAPL&region=US&lang=en-US\"\n",
    "    feed = feedparser.parse(rss_url)  # Parse the RSS feed\n",
    "    news_items = []\n",
    "    # Loop over each entry in the feed\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title  # Get the article title\n",
    "        # Get the summary if it exists; otherwise, use an empty string\n",
    "        summary = entry.summary if hasattr(entry, 'summary') else \"\"\n",
    "        # Combine title and summary to form full text\n",
    "        text = title + \". \" + summary\n",
    "        # Append the news article as a dictionary with a default sentiment label \"neutral\"\n",
    "        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"Yahoo Finance\"})\n",
    "    return news_items\n",
    "\n",
    "# Function to fetch news from Reuters Business News RSS feed\n",
    "def fetch_reuters_finance():\n",
    "    rss_url = \"http://feeds.reuters.com/reuters/businessNews\"\n",
    "    feed = feedparser.parse(rss_url)\n",
    "    news_items = []\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title\n",
    "        summary = entry.summary if hasattr(entry, 'summary') else \"\"\n",
    "        text = title + \". \" + summary\n",
    "        # Specify source as Reuters\n",
    "        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"Reuters\"})\n",
    "    return news_items\n",
    "\n",
    "# Function to fetch news from CNBC RSS feed\n",
    "def fetch_cnbc_finance():\n",
    "    rss_url = \"https://www.cnbc.com/id/100003114/device/rss/rss.html\"\n",
    "    feed = feedparser.parse(rss_url)\n",
    "    news_items = []\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title\n",
    "        summary = entry.summary if hasattr(entry, 'summary') else \"\"\n",
    "        text = title + \". \" + summary\n",
    "        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"CNBC\"})\n",
    "    return news_items\n",
    "\n",
    "# Function to fetch news from MSN Finance RSS feed\n",
    "def fetch_msn_finance():\n",
    "    # Example URL for MSN Money RSS feed (adjust URL if needed)\n",
    "    rss_url = \"https://www.msn.com/en-us/money/rss\"\n",
    "    feed = feedparser.parse(rss_url)\n",
    "    news_items = []\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title\n",
    "        summary = entry.summary if hasattr(entry, 'summary') else \"\"\n",
    "        text = title + \". \" + summary\n",
    "        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"MSN Finance\"})\n",
    "    return news_items\n",
    "\n",
    "# Function to fetch finance-related news from Google News (proxy for Google Finance)\n",
    "def fetch_google_finance():\n",
    "    # Google News RSS feed URL for finance search query\n",
    "    rss_url = \"https://news.google.com/rss/search?q=finance&hl=en-US&gl=US&ceid=US:en\"\n",
    "    feed = feedparser.parse(rss_url)\n",
    "    news_items = []\n",
    "    for entry in feed.entries:\n",
    "        title = entry.title\n",
    "        summary = entry.summary if hasattr(entry, 'summary') else \"\"\n",
    "        text = title + \". \" + summary\n",
    "        news_items.append({\"text\": text, \"label\": \"neutral\", \"source\": \"Google News\"})\n",
    "    return news_items\n",
    "\n",
    "# Function to merge all articles from the different sources\n",
    "def merge_all_articles():\n",
    "    # Call each individual fetch function\n",
    "    yahoo_articles = fetch_yahoo_finance()\n",
    "    reuters_articles = fetch_reuters_finance()\n",
    "    cnbc_articles = fetch_cnbc_finance()\n",
    "    msn_articles = fetch_msn_finance()\n",
    "    google_articles = fetch_google_finance()\n",
    "    \n",
    "    # Combine all article lists into one\n",
    "    all_articles = yahoo_articles + reuters_articles + cnbc_articles + msn_articles + google_articles\n",
    "    return all_articles\n",
    "\n",
    "# Main execution block: merge articles and save as CSV\n",
    "if __name__ == \"__main__\":\n",
    "    articles = merge_all_articles()  # Get merged list of articles\n",
    "    # Convert the list of dictionaries into a pandas DataFrame\n",
    "    df = pd.DataFrame(articles)\n",
    "    # Save DataFrame to CSV file named 'sample_data.csv'\n",
    "    df.to_csv(\"sample_data.csv\", index=False)\n",
    "    print(\"Merged sample_data.csv created with\", len(df), \"entries\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
